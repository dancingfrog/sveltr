---
title: README
author: 'John Hall'
date: '2021-02-14'
draft: false
categories:
  - Covid
  - Covid-19
  - Death
  - Mortality
  - R
tags:
  - R Markdown
always_allow_html: true
output:
  html_document:
    keep_md: yes
params:
  target_html: TRUE
---
# Develop a data visualization application

  _"We are trying to get a sense of your ability to turn data into a functional web application. We would rather see something cool than have you just follow the instructions."_

### Approach

Starting off by thinking about the purely technological side of this activity, I would like to make use of some lightweight framework and tooling for this application. My favorite frontend library of late has been SvelteJS, so I will continue to explore that solution. On the backend, while I have a lot of experience with PostgreSQL/PostGIS and  have even set up a few GeoServers over the years, I really want to take advantage of the fact that this data is already stored in "the cloud" thanks to Carto. I actually do not have much experience beyond fetching simple basemaps from Carto, so again, this will be a great learning opportunity. I would also like to move some or all of the data into Elasticsearch and make use of its excellent filtering and aggregation features. This last preference may require a very thin middleware server like NodeJS or Nginx to skirt around some Cross-Origin Request issues that occasionally come up.

The first step in developing this data-oriented application is to begin to grasp what or which information the data is intended to convey. The title of the dataset gives some indication of its content. I did gain some qualitative context by reading a couple articles about ["Deaths of Despair"](https://ifstudies.org/blog/deaths-of-despair-and-covid-19-what-we-know-so-far). Going beyond this, my overall sense of what kinds of experiences can be meaningfully facilitated by the information contained therein can be greatly enhanced by 1) A description of each field, 2) Knowledge of how the data was gathered and maintained, and 3) Some exploratory operations (statistical aggregation, plotting, mapping, etc.) on the dataset elements/features.

  1. A description of the fields was provided. Among these, the `database` field is described as naming the source of the given record in the dataset, which will help with step **2**. The fields labeled `geoid_co` and `geoid_st` respectively contain county and state level FIPS identifiers, which is useful for sorting and grouping the data by county/state while in its tabular form (i.e. pre-visualization filters). `the_geom` field contains geometry in a binary format, which can be transformed into GeoJSON or WKT. To minimize the size of the query response, I removed both `the_geom` and `the_geom_webmercator` from the Carto SQL request and replaced them with `ST_AsText(the_geom) as geom` (WKT), for subsequent geospatial processing.

  2. Values in the `database` field include [Underlying Cause of Death 1999-2018 - CDC Wonder](https://wonder.cdc.gov/wonder/help/ucd.html), a website maintained by the CDC which describes itself as " -level national mortality and population data," captured from death certificates. For reference, I downloaded the complete technical instructions that correspond to this dataset (_Note_: the documentation available online is for the more recent "1999 - 2019" dataset). By comparing the descriptions of the fields in the given dataset to the documentation for "Underlying Cause of Death 1999-2019", I can see that there are additional fields that have been joined to the original "Underlying Cause of Death 1999-2018" dataset in some unknown way, but presumably keyed on the location (by county FIPS) that each record represents. The values found in the cause of death field (`death_cause`) do **not** correspond to the (Cause of Death (ICD-10))[https://wonder.cdc.gov/wonder/help/ucd.html#ICD-10%20Codes] codes listed in the technical documentation, indicating that this dataset has already been transformed in some non-trivial way as compared to one of its source (i.e., "Underlying Cause of Death 1999-2018") and the concept of "Deaths of Despair" seems to come from another source entirely, along with any information relating to Covid-19. `death_cause = "DoD"` may actually be an aggregation of the other four values found in the data, but I wasn't able to determine if that is the case.

  3. R was used to read in the JSON data from Rural Innovation's Carto platform and save it to local disk:

```{r setup, cache = FALSE, echo = FALSE, include=FALSE}
options(warn = -1)
working_dir <- getwd()
print(working_dir)
print(grepl("/content", getwd(), ignore.case = TRUE))
if (grepl("/content", getwd(), ignore.case = TRUE)) {
  working_dir <- stringr::str_replace(getwd(), "/content", "")
  setwd(working_dir)
  print("")
}
if (!require("knitr")) {
  install.packages("knitr")
  library("knitr")
}
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(echo = TRUE)
```


```{r get_data, cache = FALSE, echo = TRUE}
data_file <- paste0(working_dir, "/content/data/dod_covid_county.RData")
if (!file.exists(data_file)) {
  dod_covid_county_data <- data.frame(jsonlite::fromJSON("https://ruralinnovation-admin.carto.com/api/v2/sql?q=select%20cartodb_id,fid,geoid_co,name,namelsad,st_stusps,geoid_st,st_name,land_sqmi,water_sqmi,lon,lat,acp_name,cbsa_type,rin_flag,database,geo_level,geoid_cbsa,geoid_acp,co_name,cbsa_name,cdc_urbanization,time_interval,time_period,death_cause,age_group,gender,race,population,deaths_dod,age_adjusted_rate,age_adjusted_rate_se,age_adjusted_rate_lower_95_ci,age_adjusted_rate_upper_95_ci,crude_rate,crude_rate_se,crude_rate_lower_95_ci,crude_rate_upper_95_ci,acp_image,pop,confirmed,deaths_covid,confirmed_per_100k,deaths_per_100k,ST_AsText(the_geom)%20as%20geom%20from%20%22ruralinnovation-admin%22.dod_covid_county", flatten = TRUE)$rows)
   save(dod_covid_county_data, file = data_file)
}

dataset <- load(data_file) # will import a data.frame called "dod_covid_county_data" from data_file
dod_covid_county_data <- dod_covid_county_data[order(data.frame(list(dod_covid_county_data$geoid_co))), ] # Order by County FIPS
str(dod_covid_county_data)

```
Having read portions of the "Underlying Cause of Death 1999-2019" technical documentation and looking at the data itself, I can see that there are multiple records associated with each place (county), so it would be good to filter records by an additional characteristic, in this case, Cause of Death (`death_cause`), before beginning to look deeper at each "bucket" of data that is produced.

```{r death_cause, cache = FALSE, echo = FALSE}
library(DT)
library(dplyr)
library(magrittr)

#causes <- dod_covid_county_data %>% dplyr::select(death_cause) %>% dplyr::distinct()
causes <- data.frame(list(dod_covid_county_data$death_cause)) %>% dplyr::distinct()
causes <- causes[order(causes),] # Order by alpha

showTablePreivew <- function(x) {
    data_preview <- x[c(1:5), !(names(dod_covid_county_data) %in% c("geom"))] # Exclude geometry
    if (exists("params")) {
        #if (params$target_html)
        #  DT::datatable(data_preview,
        #                extensions = 'Buttons',
        #                options = list(dom = 'rtBip', buttons = c('csv', 'excel', 'pdf'), lengthMenu = list(c(10, 10, 10, -1), c(50, 50, 100, "All")))
        #  )
        #else
          knitr::kable(data_preview)

    } else {
        head(data_preview) # View(data_preview)
    }
}

```

The five causes of death included in this data are "Alcohol", "Cirrhosis", "Drug", "Suicide", and  "DoD" ("Deaths of Despair"), again, suspecting that `death_cause = "DoD"` may be an aggregate term in respect to the other four causes. The data corresponding to each of these causes has been filtered into its own object/table using R (comments include Carto SQL queries to do the same).

```{r, cache = FALSE, echo = TRUE}
death_by_alcohol_data <- dod_covid_county_data[grepl("Alcohol", dod_covid_county_data[, 25]), ] #dod_covid_county_data %>% dplyr::filter(death_cause = "Alcohol")
#data.frame(jsonlite::fromJSON("https://ruralinnovation-admin.carto.com/api/v2/sql?q=select%20cartodb_id,fid,geoid_co,name,namelsad,st_stusps,geoid_st,st_name,land_sqmi,water_sqmi,lon,lat,acp_name,cbsa_type,rin_flag,database,geo_level,geoid_cbsa,geoid_acp,co_name,cbsa_name,cdc_urbanization,time_interval,time_period,death_cause,age_group,gender,race,population,deaths_dod,age_adjusted_rate,age_adjusted_rate_se,age_adjusted_rate_lower_95_ci,age_adjusted_rate_upper_95_ci,crude_rate,crude_rate_se,crude_rate_lower_95_ci,crude_rate_upper_95_ci,acp_image,pop,confirmed,deaths_covid,confirmed_per_100k,deaths_per_100k,ST_AsText(the_geom)%20as%20geom%20from%20%22ruralinnovation-admin%22.dod_covid_county%20where%20death_cause%20ilike%20%27Alcohol%27", flatten = TRUE)$rows)
```

<div style="overflow-x: scroll; margin-left: auto; margin-right: auto; max-width:1024px; width:100%; max-height:300px; padding-bottom:150px;">

```{r, cache = FALSE, echo = TRUE, results = 'asis'}
death_by_alcohol_data %>% showTablePreivew
```

</div>


```{r, cache = FALSE, echo = TRUE}
death_by_cirrhosis_data <- dod_covid_county_data[grepl("Cirrhosis", dod_covid_county_data[, 25]), ] #dod_covid_county_data %>% dplyr::filter(death_cause = "Cirrhosis")
#data.frame(jsonlite::fromJSON("https://ruralinnovation-admin.carto.com/api/v2/sql?q=select%20cartodb_id,fid,geoid_co,name,namelsad,st_stusps,geoid_st,st_name,land_sqmi,water_sqmi,lon,lat,acp_name,cbsa_type,rin_flag,database,geo_level,geoid_cbsa,geoid_acp,co_name,cbsa_name,cdc_urbanization,time_interval,time_period,death_cause,age_group,gender,race,population,deaths_dod,age_adjusted_rate,age_adjusted_rate_se,age_adjusted_rate_lower_95_ci,age_adjusted_rate_upper_95_ci,crude_rate,crude_rate_se,crude_rate_lower_95_ci,crude_rate_upper_95_ci,acp_image,pop,confirmed,deaths_covid,confirmed_per_100k,deaths_per_100k,ST_AsText(the_geom)%20as%20geom%20from%20%22ruralinnovation-admin%22.dod_covid_county%20where%20death_cause%20ilike%20%27Cirrhosis%27", flatten = TRUE)$rows)

```

<div style="overflow-x: scroll; margin-left: auto; margin-right: auto; max-width:1024px; width:100%; max-height:300px; padding-bottom:150px;">

```{r, cache = FALSE, echo = TRUE, results = 'asis'}
death_by_cirrhosis_data %>% showTablePreivew
```

</div>


```{r, cache = FALSE, echo = TRUE}
death_by_drug_data <- dod_covid_county_data[grepl("Drug", dod_covid_county_data[, 25]), ] #dod_covid_county_data %>% dplyr::filter(death_cause = "Drug")
#data.frame(jsonlite::fromJSON("https://ruralinnovation-admin.carto.com/api/v2/sql?q=select%20cartodb_id,fid,geoid_co,name,namelsad,st_stusps,geoid_st,st_name,land_sqmi,water_sqmi,lon,lat,acp_name,cbsa_type,rin_flag,database,geo_level,geoid_cbsa,geoid_acp,co_name,cbsa_name,cdc_urbanization,time_interval,time_period,death_cause,age_group,gender,race,population,deaths_dod,age_adjusted_rate,age_adjusted_rate_se,age_adjusted_rate_lower_95_ci,age_adjusted_rate_upper_95_ci,crude_rate,crude_rate_se,crude_rate_lower_95_ci,crude_rate_upper_95_ci,acp_image,pop,confirmed,deaths_covid,confirmed_per_100k,deaths_per_100k,ST_AsText(the_geom)%20as%20geom%20from%20%22ruralinnovation-admin%22.dod_covid_county%20where%20death_cause%20ilike%20%27Drug%27", flatten = TRUE)$rows)

```

<div style="overflow-x: scroll; margin-left: auto; margin-right: auto; max-width:1024px; width:100%; max-height:300px; padding-bottom:150px;">

```{r, cache = FALSE, echo = TRUE, results = 'asis'}
death_by_drug_data %>% showTablePreivew
```

</div>


```{r, cache = FALSE, echo = TRUE}
death_by_suicide_data <- dod_covid_county_data[grepl("Suicide", dod_covid_county_data[, 25]), ] #dod_covid_county_data %>% dplyr::filter(death_cause = "Suicide")
#data.frame(jsonlite::fromJSON("https://ruralinnovation-admin.carto.com/api/v2/sql?q=select%20cartodb_id,fid,geoid_co,name,namelsad,st_stusps,geoid_st,st_name,land_sqmi,water_sqmi,lon,lat,acp_name,cbsa_type,rin_flag,database,geo_level,geoid_cbsa,geoid_acp,co_name,cbsa_name,cdc_urbanization,time_interval,time_period,death_cause,age_group,gender,race,population,deaths_dod,age_adjusted_rate,age_adjusted_rate_se,age_adjusted_rate_lower_95_ci,age_adjusted_rate_upper_95_ci,crude_rate,crude_rate_se,crude_rate_lower_95_ci,crude_rate_upper_95_ci,acp_image,pop,confirmed,deaths_covid,confirmed_per_100k,deaths_per_100k,ST_AsText(the_geom)%20as%20geom%20from%20%22ruralinnovation-admin%22.dod_covid_county%20where%20death_cause%20ilike%20%27Suicide%27", flatten = TRUE)$rows)

```

<div style="overflow-x: scroll; margin-left: auto; margin-right: auto; max-width:1024px; width:100%; max-height:300px; padding-bottom:150px;">

```{r, cache = FALSE, echo = TRUE, results = 'asis'}
death_by_suicide_data %>% showTablePreivew
```

</div>


```{r, cache = FALSE, echo = TRUE}
death_by_dod_data <- dod_covid_county_data[grepl("DoD", dod_covid_county_data[, 25]), ] #dod_covid_county_data %>% dplyr::filter(death_cause = "DoD" )
#data.frame(jsonlite::fromJSON("https://ruralinnovation-admin.carto.com/api/v2/sql?q=select%20cartodb_id,fid,geoid_co,name,namelsad,st_stusps,geoid_st,st_name,land_sqmi,water_sqmi,lon,lat,acp_name,cbsa_type,rin_flag,database,geo_level,geoid_cbsa,geoid_acp,co_name,cbsa_name,cdc_urbanization,time_interval,time_period,death_cause,age_group,gender,race,population,deaths_dod,age_adjusted_rate,age_adjusted_rate_se,age_adjusted_rate_lower_95_ci,age_adjusted_rate_upper_95_ci,crude_rate,crude_rate_se,crude_rate_lower_95_ci,crude_rate_upper_95_ci,acp_image,pop,confirmed,deaths_covid,confirmed_per_100k,deaths_per_100k,ST_AsText(the_geom)%20as%20geom%20from%20%22ruralinnovation-admin%22.dod_covid_county%20where%20death_cause%20ilike%20%27DoD%27", flatten = TRUE)$rows)

```

<div style="overflow-x: scroll; margin-left: auto; margin-right: auto; max-width:1024px; width:100%; max-height:300px; padding-bottom:150px;">

```{r, cache = FALSE, echo = TRUE, results = 'asis'}
death_by_dod_data %>% showTablePreivew
```

</div>


#### Potential Uses

At this point, I believe that this dataset allows one to explore potential correlations between historic mortality factors/rates and the total number of deaths due to Covid-19 (in 2020), and to "drill down" on those relationships within a given location (county or metropolitan area). As I mentioned early, I can get a "feel" for ways to position the data by looking at some basic summary statistics and quick visualizations for a given bucket (i.e. "DoD" in the examples below).

```{r population_vs_dod_rate, cache = FALSE, echo = FALSE}
library(ggplot2)

time_period1999_2003 <- grepl("1999-2003", death_by_dod_data[, 24])
time_period2004_2008 <- grepl("2004-2008", death_by_dod_data[, 24])
time_period2009_2013 <- grepl("2009-2013", death_by_dod_data[, 24])
time_period2014_2018 <- grepl("2014-2018", death_by_dod_data[, 24])

# 1999 - 2003 crude death rates for Deaths of Despair
dod_rates_1999_2003 <- na.exclude(death_by_dod_data[time_period1999_2003, ])$crude_rate
print(paste0(length(dod_rates_1999_2003), " county dod rate records for 1999-2003 (death_cause = 'DoD'): "))
print(summary(dod_rates_1999_2003))

# Compare 1999- 2003 'population' summary ...
pop1999_2003 <- na.exclude(death_by_dod_data[time_period1999_2003, ])$population / 5
print(paste0(length(pop1999_2003), " county 'population' records for 1999-2003 (death_cause = 'DoD'): "))
print(summary(pop1999_2003))
# ... to 2019 'pop' summary
print("county 'pop' summary for 2019 :")
print(summary(na.exclude(death_by_dod_data[time_period1999_2003, ])$pop))

# 2004 - 2008 crude death rates for Deaths of Despair
dod_rates_2004_2008 <- na.exclude(death_by_dod_data[time_period2004_2008, ])$crude_rate
print(paste0(length(dod_rates_2004_2008), " county dod rate records for 2004-2008 (death_cause = 'DoD'): "))
print(summary(dod_rates_2004_2008))

# Compare 2004 - 2008 'population' summary ...
pop2004_2008 <- na.exclude(death_by_dod_data[time_period2004_2008, ])$population / 5
print(paste0(length(pop2004_2008), " county 'population' records for 2004-2008 (death_cause = 'DoD'): "))
print(summary(pop2004_2008))
# ... to 2019 'pop' summary
print("county 'pop' summary for 2019 :")
print(summary(na.exclude(death_by_dod_data[time_period2004_2008, ])$pop))

# 2009 - 2013 crude death rates for Deaths of Despair
dod_rates_2009_2013 <- na.exclude(death_by_dod_data[time_period2009_2013, ])$crude_rate
print(paste0(length(dod_rates_2009_2013), " county dod rate records for 2009-2013 (death_cause = 'DoD'): "))
print(summary(dod_rates_2009_2013))

# Compare 2009 - 2013 'population' summary ...
pop2009_2013 <- na.exclude(death_by_dod_data[time_period2009_2013, ])$population / 5
print(paste0(length(pop2009_2013), " county 'population' records for 2009-2013 (death_cause = 'DoD'): "))
print(summary(pop2009_2013))
# ... to 2019 'pop' summary
print("county 'pop' summary for 2019 :")
print(summary(na.exclude(death_by_dod_data[time_period2009_2013, ])$pop))

# 2014 - 2018 crude death rates for Deaths of Despair
dod_rates_2014_2018 <- na.exclude(death_by_dod_data[time_period2014_2018, ])$crude_rate
print(paste0(length(dod_rates_2014_2018), " county dod rate records for 2014-2018 (death_cause = 'DoD'): "))
print(summary(dod_rates_2014_2018))

# Compare 2014-2018 'population' summary ...
pop2014_2018 <- na.exclude(death_by_dod_data[time_period2014_2018, ])$population / 5
print(paste0(length(pop2014_2018), " county 'population' records for 2014-2018 (death_cause = 'DoD'): "))
print(summary(pop2014_2018))
# ... to 2019 'pop' summary
print("county 'pop' summary for 2019 :")
print(summary(na.exclude(death_by_dod_data[time_period2014_2018, ])$pop))

```

_For each county record the `population` value appears to be the sum of 5 years worth of population estimates, as compared to the single year (2019) estimate stored in `pop`._

```{r covid_deaths_vs_dod_rate, cache = FALSE, echo = FALSE}

plot_population_vs_dod_rate <- function(population, dod_rate, covid_death_rate, years){
    options(repr.plot.width=4, repr.plot.height=3.5) # Set the initial plot area dimensions
    df <- data.frame(population, dod_rate, covid_death_rate)
    df <- df[order(df$population), ]
    p <- ggplot(df, aes(x = dod_rate, y = covid_death_rate)) +
            geom_point(stroke = 1, shape = 23, aes(size = population, fill = dod_rate), alpha = 0.5) +
            scale_fill_gradient(low = "#56B4E9", high = "#E69F00") +
            ggtitle(paste0("Covid Death Rate (2020) vs. Historic DoD Rate (", years, ") per 100k ppl"))
    print(p)
}

plot_population_vs_dod_rate(pop1999_2003, dod_rates_1999_2003, na.exclude(death_by_dod_data[time_period1999_2003, ])$deaths_per_100k, "1999 - 2003")
plot_population_vs_dod_rate(pop2004_2008, dod_rates_2004_2008, na.exclude(death_by_dod_data[time_period2004_2008, ])$deaths_per_100k, "2004 - 2008")
plot_population_vs_dod_rate(pop2009_2013, dod_rates_2009_2013, na.exclude(death_by_dod_data[time_period2009_2013, ])$deaths_per_100k, "2009 - 2013")
plot_population_vs_dod_rate(pop2014_2018, dod_rates_2014_2018, na.exclude(death_by_dod_data[time_period2014_2018, ])$deaths_per_100k, "2014 - 2018")
```

What's really intresting to me is that the extreme outliers on these plots have relatively high rates of "Deaths of Despair" when compared to the population, making me wonder if there is something else in the dataset (location? demographics?) that might help to shine light on why the rates are so high.


### Preperation for Web/Visualization

Regarding mapping and visualization of this dataset, it is possible to take advantage of the existing store (Carto) which has already spatially indexed the data and offers a nice SQL-like DSL to perform queries. However, I also want to make use of the extensive search, filter and aggregation capabilities of Elasticsearch and although ES can also index features/records by geospatial coordinates, it's tesselation processor was having a hard time with this particular dataset because some geometry values produce this error:

    {
      "error": {
        "root_cause": [
          {
            "type": "mapper_parsing_exception",
            "reason": "failed to parse field [geom] of type [geo_shape]"
          }
        ],
        "type": "mapper_parsing_exception",
        "reason": "failed to parse field [geom] of type [geo_shape]",
        "caused_by": {
          "type": "illegal_argument_exception",
          "reason": "Unable to Tessellate shape ...


To work around the error above, I have computed the bounding box and bound it to the data as an additional column before indexing in Elasticsearch. This way, ES can ignore the geom field, but still be respond to spatial queries for the features in this dataset:

```{r geojson, cache = FALSE, echo = FALSE}
options(warn = -1)
if (!require(geojsonio)) {
    devtools::install_github("ropensci/wicket", upgrade = FALSE)
    devtools::install_github("jeroen/V8", upgrade = FALSE)
    devtools::install_github("ropensci/jqr", upgrade = FALSE)
    devtools::install_github("ropensci/geojson", upgrade = FALSE)
    devtools::install_github("ropensci/geojsonio", upgrade = FALSE)
}

```

```{r elasticsearch, cache = FALSE, echo = TRUE}
options(warn = -1)
if (!require(elasticsearchr)) {
    devtools::install_github("alexioannides/elasticsearchr", upgrade = FALSE)
}
library(elasticsearchr)
library(geojson)
library(geojsonio)
library(rgeos)
library(wicket)

# Setup each Elasticsearch index with the following minimal mapping:

## The old way
#PUT dod_covid_county?include_type_name=true
#{
#    "settings": {
#        "number_of_shards": 1
#    },
#    "mappings": {
#        "_doc": {
#            "properties": {
#                "geom_box": {
#                    "type": "shape"
#                }
#            }
#        }
#    }
#}
#
## The new way ES 7.0+
#PUT dod_covid_county
#{
#  "settings": {
#    "number_of_shards": 1
#  }
#}
#
#PUT dod_covid_county/_mapping?include_type_name=false
#{
#  "properties": {
#    "geom_box": {
#      "type": "shape"
#    }
#  }
#}


index_by_rate <- function (rate_index, rate_data) {
  # Try index
    hits <- data.frame()
    try({
        hits <- elasticsearchr::elastic("http://52.52.217.209:9200", rate_index) %search% query('{
          "match_all": {}
        }')
    })
    total <-  9999 # length(rate_data[,1]) # length(dod_covid_county_data[,1])

    if (dim(hits) == c(0, 0) || is.na(hits) || length(hits[,1]) < total) { # check length of hit is > total
        for (i in c(1:total)) {
            # Safest to index 1 record at a time... might take a while
            wkt_geom <- rate_data[c(i), ]$geom
            wkt_sp <- rgeos::readWKT(wkt_geom)
            geojson <- geojsonio::geojson_json(wkt_sp)
            bbox <- wicket::wkt_bounding(wkt_geom)
            geom_box <- data.frame(geom_box = paste0(
              "POLYGON ((",
                bbox$min_x, " ", bbox$min_y,", ", bbox$max_x, " ", bbox$min_y,", ",
                bbox$max_x, " ", bbox$max_y, ", ", bbox$min_x, " ", bbox$max_y, ", ",
                bbox$min_x, " ", bbox$min_y, "))"))
            geometry_frame <- dplyr::bind_cols(rate_data[c(i), c(1:(length(rate_data) - 1))], geom_box = geom_box, geom = geojson)
            elastic("http://52.52.217.209:9200", rate_index, "_doc")  %index% geometry_frame
            print(paste0("Indexing ", rate_index, ": ", i ," of ", total, " records complete"))
            rm(bbox)
            rm(geom_box)
            rm(geometry_frame)
        }
    }
}
```

```{r index_death_by_alcohol_data, cache = FALSE, echo = FALSE}
index_by_rate("death_by_alcohol_data", death_by_alcohol_data)

```

```{r index_death_by_cirrhosis_data, cache = FALSE, echo = FALSE}
index_by_rate("death_by_cirrhosis_data", death_by_cirrhosis_data)

```


```{r index_death_by_drug_data, cache = FALSE, echo = FALSE}
index_by_rate("death_by_drug_data", death_by_drug_data)

```


```{r index_death_by_suicide_data, cache = FALSE, echo = FALSE}
index_by_rate("death_by_suicide_data", death_by_suicide_data)

```


```{r index_death_by_dod_data, cache = FALSE, echo = FALSE}
index_by_rate("death_by_dod_data", death_by_dod_data)

```

With the data successfully imported into Elasticsearch and previously available via Carto SQL, I have enough resources to build a preliminary mapping interface and visualization tool. Please return to the [landing page](/) to see the results.

![Screenshot of Deaths of Despairs](images/deaths_of_despair.png)


# Scenarios

### 2.1 CORI Website map

A map has become a kind of dashboard in the context of a modern digital society. Very few of the digital maps that are created at this time are ever used to navigate or even to survey in the traditional sense. My experience with this tendency for information visualizations to veer towards the geographic or geospatial has been almost entirely in regards to property, commercial interests  and macro-economic analysis. Which is to say, even when the content of the map is something else, the impetus for creating and/or maintaining these new maps is often financial in nature. That preface gives me a chance to continue by saying that my first instinct would be to understand the economic motives that are driving the stakeholders a project to design or desire a new mapping application, even a small one which is intended to be embedded in a larger system. If the purpose of this interactive presentation is to convey information to a community, audience or organization, or even to go as far as persuading users to consider opportunities in their environment in a new way, then I need to become familiar with what that perspective could be. This is  a great excuse to have meaningful conversations with people, and explore their considerations and concerns. I understand that my primary role is not to directly facilitate conversations or manage peoples' engagement with one another, but I find it very helpful, sometimes in unexpected to ways, to build a foundation for my development work by participating in those type of exchanges and cultivating trust in the idea of sharing a vision. After all, the purpose of building software is to bring something into the world that previously only existed in someone else's mind, and I believe that fostering interpersonal resilience and openness to exploring other people's ideals is a key requirement in that endeavor.

My next step would be to use all of the information that has emerged as both requirements and aspiration to start making technology decisions.  Again, there are conversations that usually need to happen at this stage, but possibly with a different audience or group of stakeholders, each who may have a different orientation to these objectives. Sharing the workplace with highly experience people is an invaluable input to these efforts and I'm always interested in hearing about another way of approaching a problem. Sometimes that may require early exploration or simulation in order to understand how far a path might take us, even if we ultimately decided not to keep moving in that direction. In the context of this specific scenario, I believe that approaching the mapping app as a feature of the website, in general, as opposed to seeing as an independent "add on " component will be the best possible way to ensure that the whole experience achieves the desired effect. This means considering the aesthetic, functional and "nitty-griity" (Cost, Deployment, Code/Data Management, Due dates, etc.) of the whole package, keeping in mind that that is how users will perceive the experience. If the map is intended to collect or solicit information for users, it's essential to consider how that is done within the greater context of the whole website. Even as one or more of us begin to code and  re-code, we will return to these kinds of questions repeatedly, because that level of decision-making is just as iterative as any other aspect of the work.

At this point, I can be candid about which technology choices I recommend or simply have become more enamored with. I think Vector-based mapping platforms and tools (GeoJSON, TopoJSON, MVT) are necessarily the way to go with any new web mapping project because they offer incredible advances in performance, contextual search and in terms of the sheer volume of data that can be delivered, in contrast to the legacy raster tools. I began my response to this section by implying that maps have become something very different from what they used to be. Maps are now libraries, portfolios and play spaces, and I don't see any fundamental reason to develop a mapping application, unless it is capable of responding to these new expectations.


### 2.2 Broadband explorer

To aid in the work of expanding the broadband infrastructure of communities near and far, I think my overall strategy would center on understanding the industrial incentives that have driven us and other communities, into the present circumstance. As exciting as the development of telecommunications technology has been and continues to be, it's embedded in a social network (not FB, or not _just_ FB) of human desires, fears, and speculations and is subject to all of the trials and tribulations and moral conflagrations, just as any large and complicated industrial market persists in being difficult, if not impossible to predict. So, that's not just a big disclaimer or hedge regarding how much progress we can actually make  on this issue, but also an appeal to approach the humanistic, psychological factors of this  with the same interest to understand the dimensions of the problem as we might approach the technical and economic factors. From that perspective it might be useful to view this effort as a critical health and safety issue. Can we find information and quantitative data about quality of life and disposition, not as an effect of using technology or high-speed internet, but as a passive benefit for those who live in technological corridors when compared to those who do not. I know similar studies have been done around questions about the quality of life for those who have direct access to green spaces and open nature, but what about people who have experienced both as a part of their day-to-day environment. You can probably tell from my meandering consideration sthat there are many philosophical and psychological lenses for me to put on when exploring this subject. While I will always keep those close by, the strategies I adopt when dawning my technical/developer hat would be specific to the set of tasks that others have identified as being essential to these efforts. As stated in  my response above building relationship with others who are already centered and focused on this topic is key to finding my way.

